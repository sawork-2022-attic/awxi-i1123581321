# 开源软件架构调研——kubernetes

MG21330045

## 引言

Kubernetes，又被称为 k8s，是一个开源的容器编排平台，用于维护和调度容器化的应用使其按照需求工作。本调研报告将从以下几个方面介绍对 k8s 的调研

* 何为容器编排，以及其产生的背景
* k8s 的整体架构
* k8s 的控制平面
* k8s 的工作节点

## 容器编排

要讲容器编排就要讲什么是容器。容器技术是随着服务的部署技术发展应运而生的。

最早期，软件服务直接被部署在物理机器上，即操作系统运行于硬件之上，而应用软件直接运行在操作系统之上。这在机器上只运行一个应用时是没有问题的。但如果一台物理机器上运行多个服务，由于服务间没有资源的边界，因此会产生资源的竞争。此时资源分配完全依赖于操作系统，很可能会产生分配不均。

之后产生了虚拟化技术，能够在一台物理机器上运行多台虚拟机器。每台虚拟机上运行的服务彼此间隔离，不需要竞争资源（资源由宿主机上的 hypervisor 进行管理，为每台虚拟机分配一定量的物理机资源，在每台虚拟机的视角中其拥有本机的所有资源，就像应用视角的虚拟内存一样）。此时的虚拟化技术虚拟硬件，虚拟机在其之上运行完整的操作系统，应用再运行在虚拟机的操作系统之上。

随着时代进步，人们逐渐意识到虚拟机技术的缺陷：每台虚拟机拥有独立的操作系统虽然能更好地将运行在其上的应用进行隔离，但是也导致虚拟机实例占用资源过多（一个完整的操作系统需要的空间至少是 gb 级的）且启动时间过长，不仅如此有时候服务并不需要如此高的隔离程度。因此容器化技术便应运而生。容器可以认为是轻量级的虚拟机，不同于虚拟机运行在虚拟硬件之上，容器直接运行在宿主机的操作系统之上（linux 容器可以与宿主机操作系统共享内核，而 Windows 系统基于 hyper-v 的容器则仍需要在镜像中打包操作系统，且内核也由 hyper-v 提供，与宿主机隔离）。在操作系统和容器之间的是容器的运行时（container runtime），负责将容器之间彼此隔离。容器也像虚拟机一样拥有自己的文件系统、cpu、内存以及进程空间，但是容器相较于虚拟机占用资源更少，启动也更快，因此成为了主流的部署方式。

容器的基本思想是通过声明式的方式创建不可变的镜像（image），随后运行时从镜像创建动态的容器（container）。这种思想为部署服务带来了一系列好处，如容器可以简单地基于不可变的镜像回滚重启。镜像的打包可以在开发阶段完成，而运维部署时只需要镜像即可部署，解耦了开发过程和部署过程。不仅如此，容器运行于容器运行时，与宿主系统无关，因此大大简化了环境的配置工作，使得开发、测试、部署可以在同一环境下进行。

现在的服务都需要高可用，且性能可伸缩，这都可以通过容器技术实现。如果服务宕机，则可以立即关闭服务的容器并从镜像中重启一个新的容器；如果短时间内访问压力突然增大，则可以立即启动几个新的容器并将访问流量分配到这几个新的容器上进行处理。但是上述过程如果靠人手动进行处理，在容器数量增长到几千几万个时是不现实的，因此容器自动化编排的需求便产生了，这也是 k8s 出现的契机。

k8s 可以将大量容器的编排需求自动化实现，包括服务发现，负责均衡，自动部署，自动回滚，自我修复等。且 k8s 采用一种声明式而非命令式的方式控制容器的编排，即用户不需要显式指明：”启动两个 nginx 服务，如果有服务宕机了则停止宕机的容器并启动新的容器“，而只需要声明：”我需要系统中有两个 nginx 服务可用”，则 k8s 便会自动（且静默）地实现上述要求，并且在服务宕机时自动进行修复重启。

接下来将介绍 k8s 是如何实现容器的编排。

## Kubernetes 架构

容器部署技术天生是适合分布式的，因此 k8s 也是一个分布式的容器编排平台。粗略的来讲，k8s 就是由一系列节点组成的集群。k8s 负责容器的编排工作，则如同大部分其他分布式系统一样，k8s 也可以分为负责具体容器管理的部分和负责集群整体管理的部分。

以下是来自 k8s 官方文档的架构介绍图

![Kubernetes 的组件](https://d33wubrfki0l68.cloudfront.net/2475489eaf20163ec0f54ddc1d92aa8d4c87c96b/e7c81/images/docs/components-of-kubernetes.svg)

首先是负责容器管理的部分，在 k8s 中被称为节点（Node），这里的节点可以位于一台物理机，也可以位于一台虚拟机。集群中至少要有一个节点才能正常工作。其次还有一系列组件负责管理集群的运行以及集群中容器化应用的编排，这一系列组件的集合被称为控制平面（control plane）。虽然通常的做法是选择一个机器在其上启动控制平面组件，并且该节点不运行容器化应用，但生产环境中为了提高可用性也可以将控制平面分布在集群中的多台机器上。

k8s 会向外界暴露两类接口，一类是运行在集群中的容器化应用的接口，使用应用的用户可以访问服务而不需要知道集群的存在；另一类则是管理集群的接口，负责对集群发出指令和获取集群的状态。

接下来将从负责容器管理的工作节点和负责集群管理的控制平面两个方向分别介绍 k8s 的理念和实现

## 容器管理：Node

k8s 是一个实现容器自动化编排的集群，其管理对象就是容器化的应用。在 k8s 的概念中，管理的最小单位被称为 Pod，Pod 是一个或多个容器，共享存储、网络、运行策略。Pod 中的应用总是紧密耦合的，并且在管理时会一起进行状态的改变。如果是松耦合的服务，则一般每个服务单独创建一个 Pod。Pod 可以方便地进行横向扩展，就像容器的横向扩展一样，创建多个 Pod 即可。

节点的工作就是调度运行在该节点上的 Pod，因此节点上最基础的组件就是容器的运行时。容器运行时确保了 Pod 中的容器能正常在节点上启动运行。最常见的运行时就是 Docker Engine，但只要是符合容器运行时接口（CRI）的运行时 k8s 均能支持。

有了容器运行时之后 Pod 中的容器能够运行，但 Pod 并不能凭空生成。Pod 的管理是由另一个运行在节点上的重要组件：kubelet 实现的。kubelet 负责了绝大多数的集群实际工作，包括

* 向集群注册自身
* 管理 Pod 的生命周期

向集群注册实际上就是向控制平面注册，除了靠 kubelet 自身注册以外，管理者也可以手动向集群内加入节点。kubelet 注册后就可以将信息反馈给集群的控制平面，包括自身的计算资源（cpu，内外存……）和之后 Pod 的运行状态，控制平面则根据这些信息进行集群的管理。

kubelet 根据来自控制平面的信息进行 Pod 的管理。k8s 使用声明式的方式管理集群内的容器，管理者会向集群提交一个 Spec，也就是容器化应用的**期望状态**，这些信息在经过调度后会被分配至集群内具体的节点上，spec 被发送给 kubelet，kubelet 根据 spec 创建 Pod 并监视其运行，且向控制平面反馈运行状态。除了接收来自控制平面的 pod 信息，kubelet 也可以监视文件系统中的目录或是某个 http endpoint，以定期轮循的方式更新自身的 pod spec。

在集群中，节点之间彼此顺畅的通信也是十分必要的。因此在节点上还有一个重要组件运行，也就是 kube-proxy。kube-proxy 正如其名，负责整个集群内的通信和网络转发，以及一些简单的负载均衡。在 k8s 集群中，每个 pod 会分配一个 ip 和端口。正如前文所说，k8s 会向外界暴露出集群中所运行容器化应用的接口。当然可以直接通过 ip 和端口访问 Pod 的服务，但是 Pod 是动态易变的，如 Pod 失效时 k8s 并不会尝试修复而是直接创建新的 Pod，且进行横向扩展时也会产生新的 Pod，在这些过程中 Pod 的 ip 都会发生动态的变化。为了能够稳定地访问到集群提供的服务，k8s 提出了新的概念：服务（service），服务就是对集群内容器所提供的服务的抽象。服务拥有稳定的 ip 地址，当外界请求到达服务时，会被转发给真正运行服务的 Pod，在此过程中不仅隐藏了 Pod 的动态变化，还能起到负载均衡的作用，同时也方便了 Pod 的水平扩展。k8s 使用标签+选择器的方式建立服务和 Pod 的联系，即每个 Pod 都可以选择性地加上标签，而服务则指定标签，所有带有标签的 Pod 都属于该服务，就像 CSS 中的 selector 一样。Pod 可以通过标签的修改来动态加入或退出服务，而这些动态信息的维护，也是通过 kube-proxy 实现的。

有了带有容器运行时，运行 kubelet 和 kube-proxy 的节点，k8s 就拥有了能够运行 Pod，管理 Pod，Pod 和节点间通信的基石。剩下的就是使系统真正动起来，这也是控制平面将要完成的工作。

## 集群管理：control plane

控制平面是一系列组件的集合，这些组件可以运行在集群中的一个节点上，形成主节点，也可以提高可用性，配置在集群中的多个节点之上。

控制平面提供一个统一的接口用于访问，也就是组件：api-server。这里的访问指两个方面，其一是管理者访问集群的控制平面，其二是集群内部的节点访问控制平面。控制平面内的其他组件并不向外界暴露接口，而只能由 api-server 进行访问。这样做的好处是可以由 api-server 进行统一的鉴权。不仅如此，api-server 通过一个 HTTPS 端口监听请求，这样确保了集群中组件和 Pod 向 api-server 进行的通信都是安全的。用户可以通过 kubectl 之类的工具访问 api-server，从而对集群进行控制。api-server 同样可以运行多个实例横向扩展，在提升可用性的同时也可以对访问 api-server 的流量进行负载均衡。

api-server 只起到暴露接口的功能，实际上的工作由其他组件完成。集群本身需要维护很多状态，包括自身的运行状态和管理者提交的 Pod 配置信息等。这些信息都存储在一个组件中，即 etcd。etcd 是集群使用的高性能数据库，使用键值对的形式存储数据。通常 etcd 会组成集群以提高可用性，避免数据库的单点失效导致集群瘫痪。

除此之外一个重要的组件是 scheduler，该组件负责具体的 Pod 调度编排。前文中提到了 kubelet 会向控制面板反馈自身的计算资源情况，包括 cpu，内存，磁盘等。scheduler 则根据反馈的信息决定要将**新创建**的未分配的 Pod 分配至哪个节点运行。scheduler 只负责调度 Pod 创建的相关调度，集群运行状态的维护则是由其他组件控制。

控制平面中还有一个重要的组件称为 controller manager，以及一个可选的 cloud controller manager，这两个组件都用于管理被称为控制器（controller）的组件。k8s 语境中的控制器并非 MVC 中的控制器，而是采用了数字电路和机器人中控制电路的思想。控制器是一个仅依赖于集群当前状态的自动机，负责监控集群的状态并且确保集群能够按照声明的 spec 达到用户所期望的状态。控制器的工作过程就是一个集群向控制器反馈信息，控制器再根据信息发出控制动作的循环，就像现实生活中根据传感器信息控制机房温度的恒温器一样。

最常见的控制器就是 Deployment（代替了原本的 Replication Controller），该控制器确保集群中总有一定数量的 Pod 在运行，如果多了则停止新增的 Pod，少了则启动新的 Pod。以及 DaemonSet，该控制器确保集群中每个节点上都运行一个指定 Pod，常用于日志的收集或是资源的监控。不同于 Deployment 等需要保证 Pod 一直可用，Job 和 CronJob 控制器则是负责（周期性）运行一次性任务的控制器（k8s 使用声明式，用户只能声明有一次性任务运行，然后交由 api-server 提交为集群的 spec，再由 Job 控制器运行该任务。用户不能直接命令集群运行任务）

虽然大部分控制器都是不依赖状态的，但仍有支持状态保存的控制器 StatefulSet，该控制器可以确保 Pod 经过调度后仍能访问相同的持久化数据，或是仍能使用之前的 ip 或域名。StatefulSet 也支持有序地启动/停止多个 Pod

k8s 中所有对象都具有其期望状态 spec，Pod 只是集群中需要管理对象的一大部分，除了 Pod，节点本身也会通过 Node Controller 进行管理，确保其正常运行，以及维护节点的加入与退出。除此之外也有许多其他的控制器，所有控制器共同作用，使得集群状态趋向于管理者定义的集群 spec。

controller manager 管理集群内部的控制器，而 cloud controller manager 则是管理与云服务相关的控制器，云服务相关的控制器提供了集群和部署集群的云服务厂商之间的桥梁，使得 k8s 可以在多种不同的云平台集成。一个最常见的例子是节点控制器可以在云平台创建了新的服务器实例后将其加入集群注册为节点。

上述组件构成了 k8s 集群的控制平面的主要部分。所有组件通力合作，基于节点提供的容器调度实现和通信功能，使得集群能够自动化实现编排容器和管理容器。由此可以得出 k8s 的完整工作流程

* 管理者定义集群需要达到的期望状态，也即 spec
* 使用工具（如 kubectl）将 spec 提交至 api-server
* api-server 将 spec 存储在 etcd 中
* 基于 scheduler 的调度，集群将状态趋向于 spec 定义的状态
* 在运行过程中控制器监视集群状态，并使得集群状态向定义的状态趋近

## 总结

以上介绍了对 kubernetes 的架构的调研，在其中加入了个人对其理念和实现方式的理解。k8s 的架构实现在我看来非常精妙，使用声明式+控制器的方式大大减轻了管理者的编排工作量。且 k8s 的集群管理体现了类似面向切面编程的思想，虽然集群本身组织成分布式的主从结构，但每个控制器只关注自身监控状态形成的切面，如 Pod 的控制器只关注所有 Pod 的运行状态，不需要了解集群中的节点状态或是节点的资源状态。在对 k8s 进行管理时，也不需要注意集群具体的运行情况，只需要关注需要管理的资源形成的切面即可。在我看来，这为其他分布式管理系统的设计提供了很大的启发。